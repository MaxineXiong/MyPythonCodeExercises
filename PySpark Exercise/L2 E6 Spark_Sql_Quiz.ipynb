{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Key to the Data Frame Programming Quiz\n",
    "\n",
    "Helpful resources:\n",
    "http://spark.apache.org/docs/latest/api/python/pyspark.sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "\n",
    "findspark.init(os.environ['SPARK_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Spark SQL Quiz').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log = spark.read.json('data/sparkify_log_small.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_log.createOrReplaceTempView('user_log_sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\" (empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            page|\n",
      "+----------------+\n",
      "|Submit Downgrade|\n",
      "|       Downgrade|\n",
      "|          Logout|\n",
      "|   Save Settings|\n",
      "|        Settings|\n",
      "|        NextSong|\n",
      "|         Upgrade|\n",
      "|           Error|\n",
      "|  Submit Upgrade|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"SELECT DISTINCT page\n",
    "    FROM user_log_sql\n",
    "    WHERE page NOT IN (SELECT DISTINCT page FROM user_log_sql WHERE userId = '')\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?\n",
    "\n",
    "Both Spark SQL and Spark Data Frames are part of the Spark SQL library. Hence, they both use the Spark SQL Catalyst Optimizer to optimize queries. \n",
    "\n",
    "You might prefer SQL over data frames because the syntax is clearer especially for teams already experienced in SQL.\n",
    "\n",
    "Spark data frames give you more control. You can break down your queries into smaller steps, which can make debugging easier. You can also [cache](https://unraveldata.com/to-cache-or-not-to-cache/) intermediate results or [repartition](https://hackernoon.com/managing-spark-partitions-with-coalesce-and-repartition-4050c57ad5c4) intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"SELECT DISTINCT userId\n",
    "    FROM user_log_sql\n",
    "    WHERE gender = 'F'\n",
    "    \"\"\"\n",
    ").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"SELECT DISTINCT song\n",
    "    FROM user_log_sql\n",
    "    WHERE artist = (\n",
    "        SELECT artist\n",
    "        FROM user_log_sql\n",
    "        WHERE artist <> 'null'\n",
    "        GROUP BY artist\n",
    "        ORDER BY COUNT(*) DESC\n",
    "        LIMIT 1\n",
    "    )\n",
    "    \"\"\"\n",
    ").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg_interval_songs|\n",
      "+------------------+\n",
      "|               7.0|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"SELECT ROUND(AVG(z.num_songs)) AS avg_interval_songs\n",
    "    FROM \n",
    "    (\n",
    "        SELECT y.userId, y.session, COUNT(*) AS num_songs\n",
    "        FROM\n",
    "        (\n",
    "            SELECT *, SUM(x.is_home) OVER (PARTITION BY x.userId \n",
    "                                           ORDER BY x.ts \n",
    "                                           ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session\n",
    "            FROM\n",
    "            (\n",
    "                SELECT userId, ts, page, song, IF(page='Home', 1, 0) AS is_home\n",
    "                FROM user_log_sql\n",
    "                WHERE userId <> '' AND page IN ('NextSong', 'Home')\n",
    "                ORDER BY userId, ts\n",
    "            ) AS x\n",
    "        ) AS y\n",
    "        WHERE y.page <> 'Home'\n",
    "        GROUP BY y.userId, y.session\n",
    "    ) AS z\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the top 5 users who listen to songs the most on average between visiting home page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|userId|avg_interval_songs|\n",
      "+------+------------------+\n",
      "|  1579|              60.0|\n",
      "|   462|              58.5|\n",
      "|  2867|              56.0|\n",
      "|  2002|              49.0|\n",
      "|   445|              49.0|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"SELECT z.userId, AVG(z.num_songs) AS avg_interval_songs\n",
    "FROM\n",
    "    (\n",
    "        SELECT y.userId, y.session, COUNT(*) AS num_songs\n",
    "        FROM\n",
    "        (\n",
    "            SELECT *, SUM(x.is_home) OVER (PARTITION BY x.userId \n",
    "                                           ORDER BY x.ts \n",
    "                                           ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS session\n",
    "            FROM\n",
    "            (\n",
    "                SELECT userId, ts, page, song, IF(page='Home', 1, 0) AS is_home\n",
    "                FROM user_log_sql\n",
    "                WHERE userId <> '' AND page IN ('NextSong', 'Home')\n",
    "                ORDER BY userId, ts\n",
    "            ) AS x\n",
    "        ) AS y\n",
    "        WHERE y.page <> 'Home'\n",
    "        GROUP BY y.userId, y.session\n",
    "    ) AS z\n",
    "GROUP BY z.userId\n",
    "ORDER BY avg_interval_songs DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
